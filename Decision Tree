import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# Load and preprocess data
data = pd.read_csv('/content/thyroid.csv')  # Adjust the path to your dataset if necessary

# Separate features and target
X = data.drop('class', axis=1)
y = data['class']

# Check the distribution of the target variable
class_counts = y.value_counts()

# Filter out classes with fewer than 2 instances
valid_classes = class_counts[class_counts >= 2].index
filtered_data = data[data['class'].isin(valid_classes)]

# Separate features and target again
X = filtered_data.drop('class', axis=1)
y = filtered_data['class']

# Identify categorical columns
categorical_cols = X.select_dtypes(include=['object']).columns
numerical_cols = X.select_dtypes(exclude=['object']).columns

# Preprocessing for numerical data
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Preprocessing for categorical data
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Preprocess the data
X_preprocessed = preprocessor.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, stratify=y, random_state=42)

# Initialize the model
model = DecisionTreeClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Compute per-class sensitivity and specificity
tp = np.diag(conf_matrix)
fn = np.sum(conf_matrix, axis=1) - tp
fp = np.sum(conf_matrix, axis=0) - tp
tn = np.sum(conf_matrix) - (tp + fn + fp)

sensitivity_per_class = tp / (tp + fn)
specificity_per_class = tn / (tn + fp)

# Compute overall sensitivity and specificity
overall_sensitivity = np.mean(sensitivity_per_class)
overall_specificity = np.mean(specificity_per_class)

# Compute error rate
error_rate = 1 - accuracy

print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall (Sensitivity): {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Overall Sensitivity: {overall_sensitivity:.4f}')
print(f'Overall Specificity: {overall_specificity:.4f}')
print(f'Error Rate: {error_rate:.4f}')

# Perform cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model, X_preprocessed, y, cv=cv, scoring='accuracy')

print(f'Cross-Validation Accuracy Scores: {cv_scores}')
print(f'Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}')
print(f'Standard Deviation of Cross-Validation Accuracy: {cv_scores.std():.4f}')
